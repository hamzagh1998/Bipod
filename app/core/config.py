import os
import logging
import platform
import subprocess
from typing import Literal
from pydantic import Field, computed_field
from pydantic_settings import BaseSettings, SettingsConfigDict

logger = logging.getLogger("bipod.config")

def detect_hardware_arch() -> str:
    """Returns 'arm64' or 'amd64' based on the system architecture."""
    machine = platform.machine().lower()
    if "arm" in machine or "aarch64" in machine:
        return "arm64"
    return "amd64"

def detect_gpu_presence() -> bool:
    """Checks if an NVIDIA GPU is accessible within the container."""
    try:
        # We check for nvidia-smi. If it fails, we assume CPU-only.
        subprocess.run(["nvidia-smi"], check=True, capture_output=True)
        return True
    except (subprocess.CalledProcessError, FileNotFoundError):
        return False

def detect_gpu_vram() -> float:
    """Returns total VRAM in GB if GPU exists, else 0.0."""
    try:
        result = subprocess.run(
            ["nvidia-smi", "--query-gpu=memory.total", "--format=csv,noheader,nounits"],
            check=True, capture_output=True, text=True
        )
        return float(result.stdout.strip()) / 1024.0
    except:
        return 0.0

def detect_gpu_name() -> str:
    """Returns the name of the first GPU if it exists, else 'CPU'."""
    try:
        result = subprocess.run(
            ["nvidia-smi", "--query-gpu=gpu_name", "--format=csv,noheader"],
            check=True, capture_output=True, text=True
        )
        return result.stdout.strip()
    except:
        return "CPU Mode"


class Settings(BaseSettings):
    model_config = SettingsConfigDict(
        env_file=".env", 
        case_sensitive=True, 
        extra="ignore"
    )

    PROJECT_NAME: str = "Bipod"
    API_V1_STR: str = "/api/v1"
    
    # --- Hardware Auto-Detection ---
    # These use default_factories to probe hardware at startup
    HARDWARE_TARGET: Literal["amd64", "arm64"] = Field(default_factory=detect_hardware_arch)
    USE_GPU: bool = Field(default_factory=detect_gpu_presence)
    GPU_NAME: str = Field(default_factory=detect_gpu_name)
    GPU_VRAM: float = Field(default_factory=detect_gpu_vram) # Total VRAM in GB
    
    # --- Storage Paths ---
    # Use /app/data if inside container, else local ./data
    DATA_DIR: str = "/app/data" if os.path.exists("/app") else os.path.join(os.getcwd(), "data")
    
    # Root of the host filesystem (mapped via Docker)
    HOST_ROOT: str = "/host" if os.path.exists("/host") else "/"

    @computed_field
    @property
    def DOCUMENTS_DIR(self) -> str:
        return os.path.join(self.DATA_DIR, "documents")

    @computed_field
    @property
    def MEMORY_DIR(self) -> str:
        return os.path.join(self.DATA_DIR, "memory")

    @computed_field
    @property
    def VECTOR_DIR(self) -> str:
        return os.path.join(self.DATA_DIR, "vector")

    @computed_field
    @property
    def GENERATED_DIR(self) -> str:
        """Directory for files created/generated by Bipod."""
        return os.path.join(self.DATA_DIR, "generated")

    @computed_field
    @property
    def UPLOADS_DIR(self) -> str:
        """Directory for temporary user uploads."""
        return os.path.join(self.DATA_DIR, "uploads")

    
    @computed_field
    @property
    def DATABASE_URL(self) -> str:
        return f"sqlite:///{self.MEMORY_DIR}/bipod_memory.db"

    @computed_field
    @property
    def OLLAMA_BASE_URL(self) -> str:
        """Dynamic Ollama URL: 'ollama' inside Docker, 'localhost' outside."""
        import socket
        host = "ollama"
        try:
            socket.gethostbyname(host)
            return f"http://{host}:11434"
        except socket.gaierror:
            return "http://localhost:11434"

    @computed_field
    @property
    def IMAGINE_API_URL(self) -> str:
        """Dynamic Imagine URL: 'imagine' inside Docker, 'localhost' outside."""
        import socket
        host = "imagine"
        try:
            socket.gethostbyname(host)
            return f"http://{host}:3333"
        except socket.gaierror:
            return "http://localhost:3333"

    
    # Brain tiers
    SMART_MODEL: str = "qwen2.5:7b"      # Best for tool calling & precision
    HEAVY_MODEL: str = "llama3.1:8b"     # High intelligence, creative baseline
    MEDIUM_MODEL: str = "llama3.2:3b"    # For standard PC / CPU fallback
    LIGHT_MODEL: str = "llama3.2:1b"     # For Pi 5 / Edge devices
    VISION_MODEL: str = "moondream"      # Specialized for image analysis
    EMBEDDING_MODEL: str = "nomic-embed-text" # Local vector embeddings

    # Imagine tiers
    IMAGINE_FLUX_MODEL: str = "flux-schnell"     # Photoreal Quality
    IMAGINE_SDXL_MODEL: str = "sdxl-lightning"   # High Quality (Fast)
    IMAGINE_SD_MODEL: str = "stable-diffusion"   # Medium Quality (SD 1.5)
    IMAGINE_TINY_MODEL: str = "dalle-mini"       # Low Quality / CPU

    @computed_field
    @property
    def ACTIVE_MODEL(self) -> str:
        """Dynamically picks the best default brain based on detected hardware."""
        if self.HARDWARE_TARGET == "arm64":
            return self.LIGHT_MODEL
        if not self.USE_GPU:
            return self.MEDIUM_MODEL
        # For GPU users, recommend the creative heavy hitter by default
        return self.HEAVY_MODEL

    @computed_field
    @property
    def ACTIVE_IMAGINE_MODEL(self) -> str:
        """Dynamically picks the best imagine model."""
        if not self.USE_GPU:
            return self.IMAGINE_TINY_MODEL
        if self.GPU_VRAM >= 12.0:
            return self.IMAGINE_FLUX_MODEL
        if self.GPU_VRAM >= 5.5: 
            return self.IMAGINE_SDXL_MODEL
        return self.IMAGINE_SD_MODEL

    # --- Auth Settings ---
    SECRET_KEY: str = "bipod-ultra-secret-key-keep-it-local" # Recommend changing this in .env
    ALGORITHM: str = "HS256"
    ACCESS_TOKEN_EXPIRE_MINUTES: int = 60 * 24 * 7 # 7 days

settings = Settings()

# Ensure directories exist on startup
os.makedirs(settings.DOCUMENTS_DIR, exist_ok=True)
os.makedirs(settings.MEMORY_DIR, exist_ok=True)
os.makedirs(settings.VECTOR_DIR, exist_ok=True)
os.makedirs(settings.GENERATED_DIR, exist_ok=True)
os.makedirs(settings.UPLOADS_DIR, exist_ok=True)